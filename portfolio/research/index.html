<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">

<meta name="description" content="San&#39;s digital space">
<title>
    An expression of my curiosity - Mi chiamo San
</title>
<link href="/sabharwal.github.io/portfolio/research/index.xml" rel="alternate" type="application/rss+xml" title="Mi chiamo San" />

<link rel="shortcut icon" href="/favicon.png">








<link rel="stylesheet" href="/sabharwal.github.io/css/main.min.e21087ed63d455214582062760fa2c1f5bee83ddc7b55837b25e9add56379370.css" integrity="sha256-4hCH7WPUVSFFggYnYPosH1vug93HtVg3sl6a3VY3k3A=" crossorigin="anonymous" media="screen">




  






<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://coconutcow.github.io/sabharwal.github.io/tn.png"/>

<meta name="twitter:title" content="An expression of my curiosity"/>
<meta name="twitter:description" content="San&#39;s digital space"/>

<meta property="og:title" content="An expression of my curiosity" />
<meta property="og:description" content="San&#39;s digital space" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://coconutcow.github.io/sabharwal.github.io/portfolio/research/" /><meta property="og:image" content="https://coconutcow.github.io/sabharwal.github.io/tn.png"/><meta property="og:site_name" content="Call me San" />



    

    
    
    
    <title>
        
        An expression of my curiosity
        
    </title>
</head>

<body>
    
    
    <header class="wrap flex-container">
        <h1>An expression of my curiosity</h1>
    </header>
    
    <main class="wrap">
        
<article class="flex-container">
    <p>Select research papers from the cadre in niche mathematical and technical areas, while working with some very smart minds.<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<blockquote>
<p><strong>Title</strong>: Sentimenter: Monitoring Sentiments of Citizens by Analyzing their Tweets</p>
<p><strong>Authors</strong>: Sanket Rajeev Sabharwal and Viviana Mascardi</p>
<p><strong>Conference</strong>: 6th Italian Conference on ICT for Smart Cities and Communities | 23-25 September, 2020 | University of Salerno - Fisciano (SA), Italy</p>
<p><strong>Abstract</strong>: In this paper we describe Sentimenter, a Twitter sentiment analyzer initially devised as a tool for helping citizens to better understand the use of Twitter by politicians, and make more informed voting decisions. The COVID-19 pandemic suggested that Sentimenter could also be used by decision makers to monitor the underlying emotional fabric of the citizens in their country, or region alike. This can thus enable appropriate decision making in order to bring this emotional instability under control - ensuring a psychological balance and mental well-being of those that make a country what it is, its people.</p>
<p><strong>Link</strong>: <a href="https://www.researchgate.net/publication/363267019_Sentimenter_Monitoring_Sentiments_of_Citizens_by_Analyzing_their_Tweets">Click here</a></p>
</blockquote>
<blockquote>
<p><strong>Title</strong>: huSync - A model and system for the measure of synchronization in small groups: A case study on musical joint action</p>
<p><strong>Authors</strong>: Sanket Rajeev Sabharwal, Manuel Varlet, Matthew Breaden, Gualtiero Volpe, Antonio Camurri, and Peter E. Keller</p>
<p><strong>Journal</strong>: IEEE Access, January 2022</p>
<p><strong>Abstract</strong>: Human communication entails subtle non-verbal modes of expression, which can be analyzed quantitatively using computational approaches and thus support human sciences. In this paper we present huSync, a computational framework and system that utilizes trajectory information extracted using pose estimation algorithms from video sequences to quantify synchronization between individuals in small groups. The system is exploited to study interpersonal coordination in musical ensembles. Musicians communicate with each other through sounds and gestures, providing nonverbal cues that regulate interpersonal coordination. huSync was applied to recordings of concert performances by a professional instrumental ensemble playing two musical pieces. We examined effects of different aspects of musical structure (texture and phrase position) on interpersonal synchronization, which was quantified by computing phase locking values of head motion for all possible within-group pairs. Results indicate that interpersonal coupling was stronger for polyphonic textures (ambiguous leadership) than homophonic textures (clear melodic leader), and this difference was greater in early portions of phrases than endings (where coordination demands are highest). Results were cross-validated against an analysis of audio features, showing links between phase locking values and event density. This research produced a system, huSync, that can quantify synchronization in small groups and is sensitive to dynamic modulations of interpersonal coupling related to ambiguity in leadership and coordination demands, in standard video recordings of naturalistic human group interaction. huSync enabled a better understanding of the relationship between interpersonal coupling and musical structure, thus enhancing collaborations between human and computer scientists.</p>
<p><strong>Link</strong>: <a href="https://ieeexplore.ieee.org/document/9869836">Click here</a></p>
</blockquote>
<blockquote>
<p><strong>Title</strong>: Analyzing directionality of influence among ensemble musicians using Granger Causality</p>
<p><strong>Authors</strong>: Sanket Rajeev Sabharwal, Arianna Musso, Matthew Breaden, Eva Riccomagno, Antonio Camurri, and Peter E. Keller</p>
<p><strong>Conference</strong>: KEER 2022, Barcelona, Spain</p>
<p><strong>Abstract</strong>: n small musical groups, performers can seem to coordinate their movements almost effortlessly in remarkable exhibits of joint action and entrainment. To achieve a common musical goal, co-performers interact and communicate using non-verbal means such as upper- body movements, and particularly head motion. Studying these phenomena in naturalistic contexts can be challenging since most techniques make use of motion capture technologies that can be intrusive and costly. To investigate an alternative method, we analyze video recordings of a professional instrumental ensemble by extracting trajectory information using pose estimation algorithms. We examine Kansei perspectives such as the analysis of non-verbal expression conveyed by bodily movements and gestures, and test for causal relationships and directed influence between performers using the Granger Causality method. We compute weighted probabilities representing the likelihood that each performer Granger Causes co- performersâ€™ movements. Effects of different aspects of musical textures were examined and results indicated stronger directionality for homophonic textures (clear melodic leader) than polyphonic (ambiguous leadership).</p>
<p><strong>Link</strong>: In print</p>
</blockquote>

</article>
<nav role="navigation">
    <ul>
        
    </ul>
</nav>


        
        
        <nav role="navigation" class="flex-container bottom-menu">
            
<hr />
<p>


    

    
        
            <a href="/sabharwal.github.io/posts">posts</a>
        
    
    
        
            &#183; 
            <a href="/sabharwal.github.io/portfolio">works</a>
        
            &#183; 
            <a href="/sabharwal.github.io/gallery">travel</a>
        
            &#183; 
            <a href="/sabharwal.github.io/about">who is San?</a>
        
    
    
    
        &#183; 
        <a href="/sabharwal.github.io/">
            main
        </a>
    

</p>
        </nav>
        
        
    </main>
    
    <footer class="flex-container footer">San&rsquo;s digital space
</footer>
    
    
</body>

</html>